---
title: "Using Copulas in the Analysis of Competing Risks"
authors: "Tomas Power, Lisa Kelly"
output:
  pdf_document: default
  html_document: default
---

```{r}
# libraries
library(copula)
library(fitdistrplus)
library(survival)
library(ggplot2)
set.seed(6)
```

# Part 1: Frank Copula & Gamma Marginals

## Data Generation

### Generate Synthetic Data with Frank Copula

We examine the use of a Frank copula to model dependency between two competing risks: loan default (the borrower failing to pay) and loan repayment (the borrower successfully repaying the loan in full). The Frank copula provides a symmetric dependence structure, meaning that dependence is modelled evenly across the entire distribution — neither early nor late loan closures are disproportionately influential.

This setting reflects real-world scenarios where the two loan closure types may be influenced by shared economic or market factors, without a strong directional bias. For example, improving economic conditions may simultaneously reduce default risk and accelerate repayment, or worsening conditions may delay repayment and increase default likelihood, meaning that both outcomes are similarly impacted across time. The Frank copula is ideal in such cases as it lacks tail dependence and instead models a more balanced, global dependency between variables.

The two loan times are drawn from gamma distributions, where both loan default and repayment are assigned the same marginal parameters to easily see patterns caused by their dependency: shape = 2 and rate = 4, corresponding to a mean closure time of 0.5 for each component. 

```{r}
# setting parameters
copula_theta <- 2
gamma_shape1 <- 2
gamma_rate1  <- 4   
gamma_shape2 <- 2
gamma_rate2  <- 4
n <- 10000
```

### Visualise Copula Dependence

A scatterplot of the sampled copula pairs $(u_1, u_2)$ confirms the symmetric nature of the Frank copula. There is no strong clustering in the tails — instead, points are evenly dispersed around the diagonal, suggesting uniform correlation across the support. This aligns with the Frank copula’s property of no tail dependence, but still permits moderate association between components.

```{r}
# copula samples
frank_cop <- frankCopula(param = copula_theta)
u <- rCopula(n, frank_cop)

# gamma marginals
T1 <- qgamma(u[, 1], shape = gamma_shape1, rate = gamma_rate1)
T2 <- qgamma(u[, 2], shape = gamma_shape2, rate = gamma_rate2)

# loan closure time 
closure_time <- pmin(T1, T2)
event_type <- ifelse(T1 < T2, 1, 2)

simulated_data <- data.frame(closure_time, event_type)
#head(simulated_data)

# copula samples
plot(u, main = "Copula Samples (Frank)", xlab = "u1", ylab = "u2", pch = 20, col = rgb(0, 0, 1, 0.2))

# frank_scatter.png
```





### Visualise Closure Times by Event Type

A histogram of closure times coloured by event type shows the distribution of observed loan closures from loan default and loan repayment. Because both marginals are identically distributed, the differentiation between causes is driven entirely by the dependency structure introduced by the copula, where the distribution of causes is more balanced over time.

```{r}
# default times
ggplot(simulated_data, aes(x = closure_time, fill = factor(event_type))) +
  geom_histogram(position = "identity", bins = 50, alpha = 0.6) +
  labs(title = "Histogram of Closure Times", x = "Time", fill = "Event Type") +
  scale_fill_manual(values = c("steelblue", "tomato"),
                    labels = c("Loan Default", "Loan Repayment"))

# histogram_closure_times.png
```


## Fit Marginals

### Extract and Fit Distributions to Each Loan Closure Cause

Fitting the marginals for each loan closure cause using a selection of candidate distributions (exponential, weibull, gamma, and log-normal), the gamma distribution was correctly identified as the best fit in both cases. This allows us to move forward with parameter estimation under correct distributional assumptions.

```{r}
# default and repayment
default <- subset(simulated_data, event_type == 1)$closure_time
repayment <- subset(simulated_data, event_type == 2)$closure_time

# candidate distributions
fit_candidates <- c("exp", "weibull", "gamma", "lnorm")
shape_tol   <- 0.2
aic_pct_tol <- 0.05

fit_dist <- function(data) {
  fits <- setNames(lapply(fit_candidates, fitdist, data = data), fit_candidates)
  aics <- sapply(fits, function(fit) fit$aic)
  best_fit <- names(which.min(aics))
  
  list(
    best_fit   = best_fit,
    parameters = fits[[best_fit]]$estimate,
    aics       = aics
  )
}

fit_default <- fit_dist(default)
fit_repayment <- fit_dist(repayment)

# best fits
cat("Loan Default best fit:", fit_default$best_fit, "\n")
cat("Loan Repayment best fit:", fit_repayment$best_fit, "\n")
```


```{r}
# parameter values for the best fits
cat("Loan Default gamma fit: shape =", fit_default$parameters["shape"], 
    " rate =", fit_default$parameters["rate"], "\n")
cat("Loan Repayment gamma fit: shape =", fit_repayment$parameters["shape"], 
    " rate =", fit_repayment$parameters["rate"], "\n")
```


### Visualise Q-Q Plots of Fitted Marginals

These plots help visually assess how well the fitted distributions match the empirical data.

Q-Q plots comparing the empirical data to the fitted gamma marginals support this result visually. Both loan default and loan repayment risks follow the gamma quantiles closely, with minor deviations in the upper tail.

```{r}
# Q-Q plots
par(mfrow = c(1, 2))
qqplot(qgamma(ppoints(length(default)), 
              shape = fit_default$parameters["shape"], 
              rate  = fit_default$parameters["rate"]),
       default,
       main = "Q-Q Plot: Default Fit (Gamma)",
       xlab = "Theoretical Quantiles", ylab = "Sample Quantiles")
abline(0, 1, col = "red")

qqplot(qgamma(ppoints(length(repayment)), 
              shape = fit_repayment$parameters["shape"], 
              rate  = fit_repayment$parameters["rate"]),
       repayment,
       main = "Q-Q Plot: Repayment Fit (Gamma)",
       xlab = "Theoretical Quantiles", ylab = "Sample Quantiles")
abline(0, 1, col = "red")

# qqplots2.png
```
## Estimate Parameters

The Frank copula was chosen for this stage of the model because it captures symmetric dependence between risks, meaning that association between loan closure times is modelled consistently across the entire distribution, rather than being concentrated in the tails. This makes it particularly appropriate for competing risks scenarios where the interaction between loan closure types is not limited to early or extreme events.

### Single Parameter Estimate (MLE)

We estimate the copula dependence parameter ($\theta$), shape parameters $(\alpha_1, \alpha_2)$ and rate parameters $(\beta_1, \beta_2)$ for the Gamma distributions using maximum likelihood estimation on the full synthetic data set.

```{r}
# conditional density for Frank copula
conditional_frank <- function(u1, u2, theta) {
  epsilon <- 1e-10
  u1 <- min(max(u1, epsilon), 1 - epsilon)
  u2 <- min(max(u2, epsilon), 1 - epsilon)
  
  g1 <- exp(-theta * u1) - 1
  g2 <- exp(-theta * u2) - 1
  g  <- exp(-theta) - 1
  
  num <- g1 * g2 + g1
  den <- g1 * g2 + g
  
  return(num / den)
}
```






```{r}
# log-likelihood function for MLE
loglik_full <- function(params, data) {
  theta   <- params[1]
  shape1  <- params[2]
  rate1   <- params[3]
  shape2  <- params[4]
  rate2   <- params[5]
  
  if (theta == 0 || shape1 <= 0 || rate1 <= 0 || shape2 <= 0 || rate2 <= 0) return(-1e10)
  
  log_lik <- 0
  for (i in 1:nrow(data)) {
    t    <- data$closure_time[i]
    type <- data$event_type[i]
    
    F1 <- pgamma(t, shape = shape1, rate = rate1)
    F2 <- pgamma(t, shape = shape2, rate = rate2)
    
    if (type == 1) {
      f1 <- dgamma(t, shape = shape1, rate = rate1)
      cond_prob <- conditional_frank(F1, F2, theta)
      p <- f1 * cond_prob
    } else {
      f2 <- dgamma(t, shape = shape2, rate = rate2)
      cond_prob <- conditional_frank(F2, F1, theta)
      p <- f2 * cond_prob
    }
    
    if (!is.finite(p) || p <= 0) return(-1e10)
    log_lik <- log_lik + log(p)
  }
  
  return(log_lik)
}

neg_loglik <- function(params, data) -loglik_full(params, data)

# optimisation
# init_params   <- c(2, 2, 4, 2, 4)
init_params   <- c(1, 1, 1, 1, 1)
lower_bounds  <- c(1e-6, 1e-6, 1e-6, 1e-6, 1e-6)
upper_bounds  <- c(100, 100, 100, 100, 100)

result <- optim(par = init_params,
                fn = neg_loglik,
                data = simulated_data,
                method = "L-BFGS-B",
                lower = lower_bounds,
                upper = upper_bounds)

# Estimated parameters
cat("Estimated theta:   ", result$par[1], "\n")
cat("Estimated shape1:  ", result$par[2], "\n")
cat("Estimated rate1:   ", result$par[3], "\n")
cat("Estimated shape2:  ", result$par[4], "\n")
cat("Estimated rate2:   ", result$par[5], "\n")
```


```{r}
# True parameters
cat("True theta:   ", copula_theta, "\n")
cat("True shape1:  ", gamma_shape1, "\n")
cat("True rate1:   ", gamma_rate1, "\n")
cat("True shape2:  ", gamma_shape2, "\n")
cat("True rate2:   ", gamma_rate2, "\n")
```




### Parameter Distribution (Bootstrap)

To assess uncertainty in the parameter estimates, we use bootstrap resampling. This gives a distribution of estimates for $\theta, \alpha_1, \beta_1, \alpha_2,$ and $\beta_2$.

```{r}
# bootstrapping 

set.seed(6)  # For reproducibility

n_boot      <- 500
sample_size <- 2000
boot_results <- matrix(NA, nrow = n_boot, ncol = 5)
colnames(boot_results) <- c("theta", "shape1", "rate1", "shape2", "rate2")

for (b in 1:n_boot) {
  sample_data <- simulated_data[sample(1:nrow(simulated_data), sample_size, replace = TRUE), ]
  
  fit <- tryCatch({
    optim(par = c(1, 2, 4, 2, 4),
          fn = neg_loglik,
          data = sample_data,
          method = "L-BFGS-B",
          lower = c(1e-6, 1e-6, 1e-6, 1e-6, 1e-6),
          upper = c(100, 100, 100, 100, 100))
  }, error = function(e) NULL)
  
  if (!is.null(fit) && fit$convergence == 0) {
    boot_results[b, ] <- fit$par
  }
}

boot_results 

# remove NA rows from failed fits
boot_results <- boot_results[complete.cases(boot_results), ]

# summary of bootstrap distribution
boot_df <- as.data.frame(boot_results)

# true parameter values
true_theta   <- copula_theta
true_shape1  <- gamma_shape1
true_rate1   <- gamma_rate1
true_shape2  <- gamma_shape2
true_rate2   <- gamma_rate2

# MLE estimates from earlier `result` object
#mle_theta   <- result$par[1]
#mle_shape1  <- result$par[2]
#mle_rate1   <- result$par[3]
#mle_shape2  <- result$par[4]
#mle_rate2   <- result$par[5]
```

```{r}
boot_df_means <- c(mean(boot_df$theta), mean(boot_df$shape1), mean(boot_df$rate1), mean(boot_df$shape2), mean(boot_df$rate2))

boot_df_means

```


### Visualise Parameter Estimates

We now visualise the distribution of bootstrap estimates for each parameter. Each plot includes a black dashed line for the known true value used to generate the synthetic data, and a red solid line representing the MLE point estimate from the full dataset. A legend is included for clarity.

```{r}

par(mfrow = c(1,1))

# theta.png
# Theta
hist(boot_df$theta, breaks = 30, col = "lightblue",
     main = expression(paste("Theta Estimates")),
     xlab = expression(theta))
abline(v = true_theta, col = "black", lwd = 2, lty = 2)
abline(v = mle_theta, col = "red", lwd = 2, lty = 2)
legend("topright", legend = c("True Value", "MLE Estimate"),
       col = c("black", "red"), lty = c(2, 2), lwd = 2)


# shape1.png
# Shape1
hist(boot_df$shape1, breaks = 30, col = "lightgreen",
     main = expression(paste("Shape[1] Estimates")),
     xlab = expression(shape[1]))
abline(v = true_shape1, col = "black", lwd = 2, lty = 2)
abline(v = mle_shape1, col = "red", lwd = 2, lty = 2)
legend("topright", legend = c("True Value", "MLE Estimate"),
       col = c("black", "red"), lty = c(2, 2), lwd = 2)


# rate1.png
# Rate1
hist(boot_df$rate1, breaks = 30, col = "salmon",
     main = expression(paste("Rate[1] Estimates")),
     xlab = expression(rate[1]))#, xlim = c(1,2)) 
abline(v = true_rate1, col = "black", lwd = 2, lty = 2)
abline(v = mle_rate1, col = "red", lwd = 2, lty = 2)
legend("topright", legend = c("True Value", "MLE Estimate"),
       col = c("black", "red"), lty = c(2, 2), lwd = 2)


# shape2.png
# Shape2
hist(boot_df$shape2, breaks = 30, col = "plum",
     main = expression(paste("Shape[2] Estimates")),
     xlab = expression(shape[2]))
abline(v = true_shape2, col = "black", lwd = 2, lty = 2)
abline(v = mle_shape2, col = "red", lwd = 2, lty = 2)
legend("topright", legend = c("True Value", "MLE Estimate"),
       col = c("black", "red"), lty = c(2, 2), lwd = 2)


# rate2.png
# Rate2
hist(boot_df$rate2, breaks = 30, col = "khaki",
     main = expression(paste("Rate[2] Estimates")),
     xlab = expression(rate[2]))
abline(v = true_rate2, col = "black", lwd = 2, lty = 2)
abline(v = mle_rate2, col = "red", lwd = 2, lty = 2)
legend("topright", legend = c("True Value", "MLE Estimate"),
       col = c("black", "red"), lty = c(2, 2), lwd = 2)
```





## Discussion

### Role in the Project

This synthetic implementation serves as a controlled environment to test and demonstrate the use of copulas — specifically the Frank copula — in modelling competing risks. By simulating data with known dependence and marginal characteristics, we were able to assess the accuracy of parameter estimation methods and validate their performance before applying them to real-world data.

### Simulation Design

We generated 10,000 observations representing time-to-event data for two competing risks: **loan defaults** and **loan repayments**. Dependence between the two loan closure types was introduced using a **Frank copula** with a known parameter of **θ = 2**, chosen for its ability to model **symmetric dependence** — appropriate for scenarios where shared risk factors influence both causes consistently over time, without concentrating in the tails.


The marginal distributions for both risks were set to **gamma**, with $\alpha_1 = 2, \beta_1 = 4$ for loan default and $\alpha_2 = 2, \beta_2 = 4$ for loan repayment. Observed closure times were the minimum of the two, with the cause recorded as the corresponding event type.



### Key Observations from Visuals

-   **Copula Scatterplot**: The Frank copula generated balanced dependence, visible as even dispersion around the diagonal in the $u_1–u_2$ scatterplot, without clustering in the tails.

-   **Histogram of Default Times**: loan closures from both causes were distributed relatively evenly over time, consistent with the identical gamma marginals.

-   **Q-Q Plots**: Gamma distribution assumptions for both causes were visually supported, with empirical quantiles aligning well with the fitted distributions.

-   **Bootstrap Histograms**: The distributions of bootstrap estimates for $\theta, \alpha_1, \beta_1, \alpha_2$ and $\beta_2$ were all centred near the MLE estimates with low spread. Visuals included the true parameter values and MLE estimates for reference.

### Comparison of MLE, Bootstrap, and True Values

|               |                |                  |                    |
|---------------|----------------|------------------|--------------------|
| **Parameter** | **True Value** | **MLE Estimate** | **Bootstrap Mean** |
| $\theta$      | 2.00           | 1.08             | 1.18               |
| $\alpha_1$    | 2.00           | 1.22             | 1.23               |
| $\beta_1$     | 4.00           | 4.98             | 5.00               |
| $\alpha_2$    | 2.00           | 1.16             | 1.17               |
| $\beta_2$     | 4.00           | 4.78             | 4.80               |



-   **MLE Estimates** showed a consistent pattern of underestimating the true shape parameters and $\theta$, with slight overestimation of the rate parameters. This reflects moderate bias, particularly in the copula component.

-   **Bootstrap Means** confirmed the stability of the MLE estimates, with distributions tightly clustered around the MLEs, but not the true values, due to the bias of our estimates.

-  The underestimation of $\theta$ likely stems from the Frank copula's lack of tail dependence, which makes dependence harder to detect in joint extremes, especially with moderate true dependence and gamma marginals.



### Conclusion

This synthetic implementation demonstrated that copula-based competing risks models can reasonably recover marginal and dependence parameters when using the Frank copula, though with increased estimation uncertainty. The results support the viability of using Frank copulas for modelling symmetric dependence, particularly in scenarios without strong tail effects.


What went well:

-   The estimation process was robust in both MLE and bootstrapping. 

-   Visual checks supported the use of gamma marginals.

Limitations:

-   Estimates for $\theta$ and the gamma shape parameters showed both bias and greater spread, likely due to the Frank copula's lack of tail dependence, highlighting limitations of full likelihood estimation in this setup.

-   The symmetric dependence structure of the Frank copula may make identification harder when dependence is moderate and not concentrated in the tails.

- Shape parameters for both marginals were also underestimated, while rate parameters were overestimated, suggesting a parameter trade-off: the model may have compensated for lighter tails (lower shape) by increasing the rate to maintain similar means.

- There is increased estimation complexity. Five parameters are being estimated simultaneously. The gamma distribution involves two interacting parameters (shape and rate), which can lead to identifiability issues. Small changes in one can compensate for changes in the other, making precise estimation harder.

Despite these limitations, the simulation provides valuable insight into the strengths and challenges of using the Frank copula for competing risks modelling, and forms a useful benchmark for further exploration with real-world data or alternative copulas, perhaps with stronger tail dependency, such as the Clayton copula.













# Part 2: Clayton Copula & Exponential Marginals

## Data Generation

### Generate Synthetic Data with Clayton Copula

We simulate two dependent failure times (T1, T2) representing loan repayment and loan default (the competing risks) using a Clayton copula to induce positive dependence.

```{r data-generation}
# Parameters
copula_theta <- 2
exp_rate1 <- 4
exp_rate2 <- 2.5
n <- 10000

# Generate copula samples
clayton_cop <- claytonCopula(param = copula_theta)
u <- rCopula(n, clayton_cop)

# Transform to exponential marginals
T1 <- qexp(u[, 1], rate = exp_rate1)
T2 <- qexp(u[, 2], rate = exp_rate2)

# Observed loan closure time and cause
closure_time <- pmin(T1, T2)
event_type <- ifelse(T1 < T2, 1, 2)  # 1 = repayment, 2 = default

# Final dataset
simulated_data <- data.frame(closure_time, event_type)
head(simulated_data)
```

### Visualize Copula Dependence

A scatterplot of copula samples (u1, u2) illustrates the dependence structure imposed by the Clayton copula.

```{r copula-scatterplot}
# clayton_scatter.png
plot(u, main = "Copula Samples (Clayton)", xlab = "u1", ylab = "u2", pch = 20, col = rgb(0, 0, 1, 0.2))
```

### Visualize Closure Times by Event Type

A histogram of closure times colored by event type shows the distribution of observed closures from repayment and default.

```{r closure-time-hist}
# histogram_closure_times2.png
ggplot(simulated_data, aes(x = closure_time, fill = factor(event_type))) +
  geom_histogram(position = "identity", bins = 50, alpha = 0.6) +
  labs(title = "Histogram of Closure Times", x = "Time", y = "Count", fill = "Event Type") +
  scale_fill_manual(values = c("steelblue", "tomato"),
                    labels = c("Repayment", "Default"))
```

## Fit Marginals

### Extract and Fit Distributions to Each Closure Cause

We split the simulated data into two groups by event type and fit several candidate distributions to each. Model selection is based on AIC, and we use shape and AIC difference tolerances to determine if an exponential fit can acceptably replace a Weibull.

```{r fit-marginals}
# Extract marginals by event type
repayment <- subset(simulated_data, event_type == 1)$closure_time
default   <- subset(simulated_data, event_type == 2)$closure_time

# Candidate distributions
fit_candidates <- c("exp", "weibull", "gamma", "lnorm")

# Tuning parameters for model selection
shape_tol   <- 0.2   # Accept exponential if Weibull shape ≈ 1 and
aic_pct_tol <- 0.05  # if AIC within 5% of exponential's AIC

# Function to fit and select best distribution
fit_dist <- function(data) {
  fits <- setNames(lapply(fit_candidates, fitdist, data = data), fit_candidates)
  aics <- sapply(fits, function(fit) fit$aic)
  best_fit <- names(which.min(aics))
  
  # Override Weibull if close to exponential
  if (best_fit == "weibull") {
    shape_diff   <- abs(fits[["weibull"]]$estimate["shape"] - 1)
    aic_diff_pct <- abs(aics["weibull"] - aics["exp"]) / abs(aics["exp"])
    
    if (shape_diff < shape_tol && aic_diff_pct < aic_pct_tol) {
      best_fit <- "exp"
    }
  }

  list(
    best_fit   = best_fit,
    parameters = fits[[best_fit]]$estimate,
    aics       = aics
  )
}

# Apply fitting function to each cause
fit_repayment <- fit_dist(repayment)
fit_default   <- fit_dist(default)

# Output best-fitting distribution for each cause
cat("Repayment best fit:", fit_repayment$best_fit, "\n")
cat("Default best fit:", fit_default$best_fit, "\n")
```

### Visualize Q-Q Plots of Fitted Marginals

These plots help visually assess how well the fitted distributions match the empirical data.

```{r qq-plots}
par(mfrow = c(1, 2))

# Repayment Q-Q plot
# qqplot2.png
qqplot(qexp(ppoints(length(repayment)), rate = fit_repayment$parameters["rate"]),
       repayment,
       main = "Q-Q Plot: Repayment",
       xlab = "Theoretical Quantiles", ylab = "Sample Quantiles")
abline(0, 1, col = "red")

# Default Q-Q plot
qqplot(qexp(ppoints(length(default)), rate = fit_default$parameters["rate"]),
       default,
       main = "Q-Q Plot: Default",
       xlab = "Theoretical Quantiles", ylab = "Sample Quantiles")
abline(0, 1, col = "red")
```

## Estimate Parameters

The Clayton copula was chosen for the final model because it models lower tail dependence, which is appropriate for competing risks scenarios where extreme (early) failure in one component may increase the likelihood of failure in the other. This reflects real-world settings where risks may be correlated during stress events, making Clayton a natural and interpretable choice.

### Single Parameter Estimate (MLE)

We estimate the copula dependence parameter (θ) and exponential rates (λ1, λ2) using maximum likelihood estimation on the full synthetic dataset.

```{r mle-estimation}
# Clayton conditional survival probability
conditional_clayton <- function(u1, u2, theta) {
  epsilon <- 1e-10
  u1 <- min(max(u1, epsilon), 1 - epsilon)
  u2 <- min(max(u2, epsilon), 1 - epsilon)
  
  term <- u1^(-theta) + u2^(-theta) - 1
  1 - term^(-(1 + 1/theta)) * u1^(-(1 + theta))
}

# Full log-likelihood for competing risks with Clayton copula
loglik_full <- function(params, data) {
  theta   <- params[1]
  lambda1 <- params[2]
  lambda2 <- params[3]
  
  if (theta <= 0 || lambda1 <= 0 || lambda2 <= 0) return(-1e10)
  
  log_lik <- 0
  for (i in 1:nrow(data)) {
    t    <- data$closure_time[i]
    type <- data$event_type[i]
    
    F1 <- 1 - exp(-lambda1 * t)
    F2 <- 1 - exp(-lambda2 * t)
    
    if (type == 1) {
      f1 <- lambda1 * exp(-lambda1 * t)
      cond_prob <- conditional_clayton(F1, F2, theta)
      p <- f1 * cond_prob
    } else {
      f2 <- lambda2 * exp(-lambda2 * t)
      cond_prob <- conditional_clayton(F2, F1, theta)
      p <- f2 * cond_prob
    }
    
    if (!is.finite(p) || p <= 0) return(-1e10)
    log_lik <- log_lik + log(p)
  }
  
  return(log_lik)
}

# Negative log-likelihood for optimization
neg_loglik <- function(params, data) -loglik_full(params, data)

# MLE optimization
init_params   <- c(1, 1, 1)
lower_bounds  <- c(1e-6, 1e-6, 1e-6)
upper_bounds  <- c(1000, 1000, 1000)

result <- optim(par = init_params,
                fn = neg_loglik,
                data = simulated_data,
                method = "L-BFGS-B",
                lower = lower_bounds,
                upper = upper_bounds)

# Output point estimates
cat("Estimated theta:   ", result$par[1], "\n")
cat("Estimated lambda1: ", result$par[2], "\n")
cat("Estimated lambda2: ", result$par[3], "\n")
```

```{r true}
# Output true values
cat("True theta:   ", copula_theta, "\n")
cat("True lambda1: ", exp_rate1, "\n")
cat("True lambda2: ", exp_rate2, "\n")
```

### Parameter Distribution (Bootstrap)

To assess uncertainty in the parameter estimates, we use bootstrap resampling. This gives a distribution of estimates for θ, λ₁, and λ₂

```{r bootstrap, cache = TRUE}
set.seed(6)

# ~13min runtime
n_boot      <- 500
sample_size <- 2000
boot_results <- matrix(NA, nrow = n_boot, ncol = 3)
colnames(boot_results) <- c("theta", "lambda1", "lambda2")

for (b in 1:n_boot) {
  sample_data <- simulated_data[sample(1:nrow(simulated_data), sample_size, replace = TRUE), ]
  
  fit <- tryCatch({
    optim(par = c(1, 1, 1),
          fn = neg_loglik,
          data = sample_data,
          method = "L-BFGS-B",
          lower = c(1e-6, 1e-6, 1e-6),
          upper = c(1000, 1000, 1000))
  }, error = function(e) NULL)
  
  if (!is.null(fit) && fit$convergence == 0) {
    boot_results[b, ] <- fit$par
  }
}

# Remove NA rows from failed fits
boot_results <- boot_results[complete.cases(boot_results), ]

# Summary of bootstrap distribution
summary(as.data.frame(boot_results))
```

### Visualize Parameter Estimates

We now visualize the distribution of bootstrap estimates for each parameter. Each plot includes a black dashed line for the known true value used to generate the synthetic data, and a red solid line representing the MLE point estimate from the full dataset.

```{r param-est-hist}
# True parameter values
true_theta   <- copula_theta
true_lambda1 <- exp_rate1
true_lambda2 <- exp_rate2

# MLE estimates from earlier `result` object
mle_theta   <- result$par[1]
mle_lambda1 <- result$par[2]
mle_lambda2 <- result$par[3]

# Convert to data frame
boot_df <- as.data.frame(boot_results)

# Theta
# theta.png
hist(boot_df$theta, breaks = 30, col = "lightblue",
     main = expression(paste("Theta Estimates")),
     xlab = expression(theta))

abline(v = true_theta, col = "black", lwd = 2, lty = 2)  # True value
abline(v = mle_theta, col = "red", lwd = 2, lty = 2)     # MLE estimate

legend("topright", legend = c("True Value", "MLE Estimate"),
       col = c("black", "red"), lty = c(2, 2), lwd = 2)

# Lambda1
# lambda1.png
hist(boot_df$lambda1, breaks = 30, col = "lightgreen",
     main = expression(paste("Lambda[1] Estimates")),
     xlab = expression(lambda[1]))

abline(v = true_lambda1, col = "black", lwd = 2, lty = 2)
abline(v = mle_lambda1, col = "red", lwd = 2, lty = 2)

legend("topright", legend = c("True Value", "MLE Estimate"),
       col = c("black", "red"), lty = c(2, 2), lwd = 2)

# Lambda2
# lambda2.png
hist(boot_df$lambda2, breaks = 30, col = "salmon",
     main = expression(paste("Lambda[2] Estimates")),
     xlab = expression(lambda[2]))

abline(v = true_lambda2, col = "black", lwd = 2, lty = 2)
abline(v = mle_lambda2, col = "red", lwd = 2, lty = 2)

legend("topright", legend = c("True Value", "MLE Estimate"),
       col = c("black", "red"), lty = c(2, 2), lwd = 2)
```

## Discussion

### Role in the Project

This synthetic implementation serves as a controlled environment to test and demonstrate the use of copulas — specifically the Clayton copula — in modeling competing risks. By simulating data with known dependence and marginal characteristics, we were able to assess the accuracy of parameter estimation methods and validate their performance.

### Simulation Design

We generated 10,000 observations representing time-to-event data for two competing risks: **loan repayment** and **loan default**. Dependence between the two failure types was introduced using a **Clayton copula** with a known parameter of **θ = 2**, chosen for its ability to model **lower tail dependence** — appropriate for scenarios where early failure in one increases the risk of failure in another.

The marginal distributions for both risks were set to **exponential**, with **λ₁ = 4** for repayment and **λ₂ = 2.5** for default. Observed closure times were the minimum of the two, with the cause recorded as the corresponding event type.

### Key Observations from Visuals

-   **Copula Scatterplot**: The Clayton copula generated clear lower tail dependence, visible as clustering in the bottom-left of the u1–u2 scatterplot.

-   **Histogram of Closure Times**: Repayments dominated early in the timeline, while default events occurred more evenly across time, consistent with their lower hazard rate.

-   **Q-Q Plots**: Exponential distribution assumptions for both causes were visually supported. The points closely followed the theoretical line, with only mild deviation in the upper tail, confirming good model fit.

-   **Bootstrap Histograms**: The distributions of bootstrap estimates for θ, λ₁, and λ₂ were all centered near their true values, with low spread.

### Comparison of MLE, Bootstrap, and True Values

(comparison.jpeg)

|               |                |                  |                    |
|---------------|----------------|------------------|--------------------|
| **Parameter** | **True Value** | **MLE Estimate** | **Bootstrap Mean** |
| θ             | 2.00           | 2.31             | 2.45               |
| λ₁            | 4.00           | 4.02             | 4.04               |
| λ₂            | 2.50           | 2.60             | 2.62               |

-   **MLE Estimates** were very close to the true values for all parameters, indicating successful recovery of model inputs.

-   **Bootstrap Means** confirmed the stability of these estimates, with distributions tightly clustered around both the true values and the MLEs.

-   **θ** showed slightly more variability across bootstrap samples, which is expected due to its more complex influence on joint behavior. Unlike the marginal rate parameters, which depend only on the individual time distributions, θ governs the dependence structure between the risks, making it more sensitive to variation in the joint tails of the data. This results in greater estimation uncertainty, especially when dependence is moderate or when sample fluctuations disproportionately affect joint failures

### Conclusion

This synthetic implementation successfully demonstrated that copula-based competing risks models can **recover true marginal and dependence parameters with high accuracy**, under ideal conditions. The results validated both the model structure and estimation approach, particularly the use of MLE and bootstrap for parameter inference.

What went well:

-   The estimation process was robust, with both MLE and bootstrap confirming parameter accuracy.

-   Visual checks supported the use of exponential marginals.

Limitations:

-   θ exhibited more spread in bootstrap results, suggesting that dependence parameters may be less stable under resampling.

-   Real-world data may introduce noise, censoring, or model violations not present in this controlled setup.

Nonetheless, this simulation provides a strong foundation for applying the same framework to empirical data.
